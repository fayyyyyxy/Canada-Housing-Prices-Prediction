{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI4XVMOGxIsd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cleaned_canada.csv')"
      ],
      "metadata": {
        "id": "ooUDRqkTxNCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocess = df.copy()"
      ],
      "metadata": {
        "id": "IXZ9GRFe0xIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "UiwWPHjzzRuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features with too many missing value\n",
        "missing_thresh = 0.6\n",
        "drop_cols = [col for col in df_preprocess.columns if df_preprocess[col].isnull().mean() > missing_thresh]\n",
        "df_preprocess.drop(columns=drop_cols, inplace=True)\n",
        "df_preprocess.drop(columns=['Acreage'], inplace=True)"
      ],
      "metadata": {
        "id": "mIuyHdx3zImC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocess_L = df_preprocess[df_preprocess['Price'] <= 2500000].copy()\n",
        "\n",
        "def categorize_province(province):\n",
        "    if province in ['ON', 'QC', 'BC']:\n",
        "        return 'High Population'\n",
        "    elif province in ['AB', 'SK', 'MB']:\n",
        "        return 'Resource Rich'\n",
        "    else:\n",
        "        return 'Small Population'\n",
        "\n",
        "df_preprocess_L['Area'] = df_preprocess_L['Province'].apply(categorize_province)"
      ],
      "metadata": {
        "id": "3KZ3dZ2lGJ2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocess_L.drop(columns=['Latitude', 'Longitude','Province'], inplace=True)"
      ],
      "metadata": {
        "id": "knICANz37M06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "num_cols = df_preprocess_L.drop(columns=['Price']).select_dtypes(include=[\"float64\", \"int\"]).columns.tolist()\n",
        "cat_cols = df_preprocess_L.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "# deal with missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df_preprocess_L[cat_cols] = imputer.fit_transform(df_preprocess_L[cat_cols])\n",
        "# OneHot Coding\n",
        "df_preprocess_L = pd.get_dummies(df_preprocess_L, columns=cat_cols, dummy_na=False)\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "df_preprocess_L[num_cols] = scaler.fit_transform(df_preprocess_L[num_cols])"
      ],
      "metadata": {
        "id": "AuxzG-wD1Koh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models (All features)"
      ],
      "metadata": {
        "id": "3kAOuKhV1n8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocess_H = df_preprocess_L[df_preprocess_L['Area_High Population'] == 1].copy()\n",
        "df_preprocess_R = df_preprocess_L[df_preprocess_L['Area_Resource Rich'] == 1].copy()\n",
        "df_preprocess_S = df_preprocess_L[df_preprocess_L['Area_Small Population'] == 1].copy()\n",
        "df_seperated = [df_preprocess_H, df_preprocess_R, df_preprocess_S]"
      ],
      "metadata": {
        "id": "iM03ODV0918F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear model\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "for df in df_seperated:\n",
        "  X = df.drop(columns=['Price'])\n",
        "  y = df['Price']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  model_lr = LinearRegression()\n",
        "  model_lr.fit(X_train, y_train)\n",
        "  y_pred_lr = model_lr.predict(X_test)\n",
        "  mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "  rmse_lr = np.sqrt(mse_lr)\n",
        "  r2_lr = r2_score(y_test, y_pred_lr)\n",
        "  norm_mse_lr = mse_lr / (max(y_test)-min(y_test))\n",
        "  print(f\"Linear Regression - MSE: {mse_lr}, RMSE: {rmse_lr}, R2: {r2_lr}, NormalizedMSE: {norm_mse_lr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_KBErm_1nTM",
        "outputId": "760287eb-33d4-4ef7-de97-89bbf6442fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - MSE: 85211238864.75107, RMSE: 291909.6416097815, R2: 0.7055210476827358, NormalizedMSE: 34849.797089996755\n",
            "Linear Regression - MSE: 28747439126.10254, RMSE: 169550.69780482337, R2: 0.7321129882290086, NormalizedMSE: 11733.648622898996\n",
            "Linear Regression - MSE: 50053367245.06465, RMSE: 223726.09871238683, R2: 0.46543294233735044, NormalizedMSE: 20463.355374106563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "for df in df_seperated:\n",
        "  X = df.drop(columns=['Price'])\n",
        "  y = df['Price']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  model_ridge = Ridge(alpha=1.0)\n",
        "  model_ridge.fit(X_train, y_train)\n",
        "  y_pred_ridge = model_ridge.predict(X_test)\n",
        "  mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "  rmse_ridge = np.sqrt(mse_ridge)\n",
        "  r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "  print(f\"Ridge Regression - MSE: {mse_ridge}, RMSE: {rmse_ridge}, R2: {r2_ridge}\")"
      ],
      "metadata": {
        "id": "jK_zsLwn5ZFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb48ab8c-a8d9-44ca-a822-3b77d87a914b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression - MSE: 85504837572.71577, RMSE: 292412.1023020692, R2: 0.7045064087562865\n",
            "Ridge Regression - MSE: 28413228076.30286, RMSE: 168562.23799031283, R2: 0.735227380402828\n",
            "Ridge Regression - MSE: 47455169390.93618, RMSE: 217842.0744276371, R2: 0.49318154465029107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "for df in df_seperated:\n",
        "  X = df.drop(columns=['Price'])\n",
        "  y = df['Price']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  model_dt = DecisionTreeRegressor(random_state=42)\n",
        "  model_dt.fit(X_train, y_train)\n",
        "  y_pred_dt = model_dt.predict(X_test)\n",
        "  mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "  rmse_dt = np.sqrt(mse_dt)\n",
        "  r2_dt = r2_score(y_test, y_pred_dt)\n",
        "  print(f\"Decision Tree - MSE: {mse_dt}, RMSE: {rmse_dt}, R2: {r2_dt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW6rwlE0L8ec",
        "outputId": "a2bbe23d-de1b-4c16-d801-273f2e6feb7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - MSE: 106130382984.83803, RMSE: 325776.5844637058, R2: 0.6332272079741649\n",
            "Decision Tree - MSE: 29359094003.932255, RMSE: 171344.95616717832, R2: 0.726413197136724\n",
            "Decision Tree - MSE: 60323208860.87674, RMSE: 245607.83550383066, R2: 0.3557516298225083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boosted tree\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "for df in df_seperated:\n",
        "  X = df.drop(columns=['Price'])\n",
        "  y = df['Price']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  model_gb = GradientBoostingRegressor(random_state=42)\n",
        "  model_gb.fit(X_train, y_train)\n",
        "  y_pred_gb = model_gb.predict(X_test)\n",
        "  mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "  rmse_gb = np.sqrt(mse_gb)\n",
        "  r2_gb = r2_score(y_test, y_pred_gb)\n",
        "  print(f\"Gradient Boosting - MSE: {mse_gb}, RMSE: {rmse_gb}, R2: {r2_gb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOutPTceciE-",
        "outputId": "2d04d5c2-c6c4-4df6-85cf-9bc46fb6b13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting - MSE: 82694836580.77115, RMSE: 287567.0992668861, R2: 0.7142174064972269\n",
            "Gradient Boosting - MSE: 30060021685.566357, RMSE: 173378.26185991816, R2: 0.7198815049996656\n",
            "Gradient Boosting - MSE: 43183030110.91613, RMSE: 207805.26968995787, R2: 0.5388077442556838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "for df in df_seperated:\n",
        "    X = df.drop(columns=['Price'])\n",
        "    y = df['Price']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model_rf = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "    model_rf.fit(X_train, y_train)\n",
        "    y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "    rmse_rf = np.sqrt(mse_rf)\n",
        "    r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "    print(f\"Random Forest - MSE: {mse_rf}, RMSE: {rmse_rf}, R2: {r2_rf}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejosO7ZcR1Xd",
        "outputId": "6227ea69-1ac1-437e-f070-1cc1977c8837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - MSE: 63768002117.929695, RMSE: 252523.27044834837, R2: 0.7796260833050631\n",
            "Random Forest - MSE: 19118491275.74569, RMSE: 138269.63251468376, R2: 0.8218416786635128\n",
            "Random Forest - MSE: 43195334124.8937, RMSE: 207834.87225413762, R2: 0.5386763381003851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "gNRKC7Vt8JFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Feature Selection (example using SelectKBest with f_regression)\n",
        "for df in df_seperated:\n",
        "    X = df.drop(columns=['Price'])\n",
        "    y = df['Price']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Select top 550 features\n",
        "    selector = SelectKBest(score_func=f_regression, k=550)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Linear Regression with selected featuress\n",
        "    model_lr_f = LinearRegression()\n",
        "    model_lr_f.fit(X_train_selected, y_train)\n",
        "    y_pred_lr_f = model_lr_f.predict(X_test_selected)\n",
        "    mse_lr_f = mean_squared_error(y_test, y_pred_lr_f)\n",
        "    rmse_lr_f = np.sqrt(mse_lr_f)\n",
        "    r2_lr_f = r2_score(y_test, y_pred_lr_f)\n",
        "    print(f\"Linear Regression (with Feature Selection) - MSE: {mse_lr_f}, RMSE: {rmse_lr_f}, R2: {r2_lr_f}\")\n",
        "\n",
        "    # Ridge Regression with selected features\n",
        "    model_ridge_f = Ridge(alpha=1.0)\n",
        "    model_ridge_f.fit(X_train_selected, y_train)\n",
        "    y_pred_ridge_f = model_ridge_f.predict(X_test_selected)\n",
        "    mse_ridge_f = mean_squared_error(y_test, y_pred_ridge_f)\n",
        "    rmse_ridge_f = np.sqrt(mse_ridge_f)\n",
        "    r2_ridge_f = r2_score(y_test, y_pred_ridge_f)\n",
        "    print(f\"Ridge Regression (with Feature Selection) - MSE: {mse_ridge_f}, RMSE: {rmse_ridge_f}, R2: {r2_ridge_f}\")\n",
        "\n",
        "    # Decision Tree with selected features\n",
        "    model_dt_f = DecisionTreeRegressor(random_state=42)\n",
        "    model_dt_f.fit(X_train_selected, y_train)\n",
        "    y_pred_dt_f = model_dt_f.predict(X_test_selected)\n",
        "    mse_dt_f = mean_squared_error(y_test, y_pred_dt_f)\n",
        "    rmse_dt_f = np.sqrt(mse_dt_f)\n",
        "    r2_dt_f = r2_score(y_test, y_pred_dt_f)\n",
        "    print(f\"Decision Tree (with Feature Selection) - MSE: {mse_dt_f}, RMSE: {rmse_dt_f}, R2: {r2_dt_f}\")\n",
        "\n",
        "    # Random Forest with Bagging with selected features\n",
        "    model_rf_f = RandomForestRegressor(n_estimators=500,random_state=42)\n",
        "    model_rf_f.fit(X_train,y_train)\n",
        "    y_pred_rf_f = model_rf_f.predict(X_test)\n",
        "    mse_rf_f = mean_squared_error(y_test, y_pred_rf_f)\n",
        "    rmse_rf_f = np.sqrt(mse_rf_f)\n",
        "    r2_rf_f = r2_score(y_test, y_pred_rf_f)\n",
        "    print(f\"Random Forest (with Feature Selection) - MSE: {mse_rf_f}, MSE: {rmse_rf_f}, R2: {r2_rf_f}\")\n",
        "\n",
        "    # Gradient boosting with selected features\n",
        "    model_gb_f = GradientBoostingRegressor(random_state=42)\n",
        "    model_gb_f.fit(X_train_selected, y_train)\n",
        "    y_pred_gb_f = model_gb_f.predict(X_test_selected)\n",
        "    mse_gb_f = mean_squared_error(y_test, y_pred_gb_f)\n",
        "    rmse_gb_f = np.sqrt(mse_gb_f)\n",
        "    r2_gb_f = r2_score(y_test, y_pred_gb_f)\n",
        "    print(f\"Gradient Boosting (with Feature Selection) - MSE: {mse_gb_f}, RMSE: {rmse_gb_f}, R2: {r2_gb_f}\")\n"
      ],
      "metadata": {
        "id": "wv8bHmhaM_Bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bdb17a-8929-4e25-e1b1-e5c16bd35754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (with Feature Selection) - MSE: 85141935874.85558, RMSE: 291790.9112272957, R2: 0.7057605497968791\n",
            "Ridge Regression (with Feature Selection) - MSE: 85482968455.69069, RMSE: 292374.7055675143, R2: 0.7045819855787274\n",
            "Decision Tree (with Feature Selection) - MSE: 108780282858.55693, RMSE: 329818.5605125293, R2: 0.6240694988626125\n",
            "Random Forest (with Feature Selection) - MSE: 63768002117.929695, MSE: 252523.27044834837, R2: 0.7796260833050631\n",
            "Gradient Boosting (with Feature Selection) - MSE: 82719466719.57874, RMSE: 287609.9211077023, R2: 0.7141322879428188\n",
            "Linear Regression (with Feature Selection) - MSE: 28661108267.063, RMSE: 169295.91922743738, R2: 0.7329174743521125\n",
            "Ridge Regression (with Feature Selection) - MSE: 28569276735.256866, RMSE: 169024.4856086149, R2: 0.7337732192598236\n",
            "Decision Tree (with Feature Selection) - MSE: 29824963054.125847, RMSE: 172699.05342567991, R2: 0.7220719315657107\n",
            "Random Forest (with Feature Selection) - MSE: 19118491275.74569, MSE: 138269.63251468376, R2: 0.8218416786635128\n",
            "Gradient Boosting (with Feature Selection) - MSE: 30082882835.31031, RMSE: 173444.17786512844, R2: 0.7196684701945932\n",
            "Linear Regression (with Feature Selection) - MSE: 51148554315.06116, RMSE: 226160.4614318364, R2: 0.45373640798169357\n",
            "Ridge Regression (with Feature Selection) - MSE: 48928807868.18368, RMSE: 221198.5711259991, R2: 0.4774431712261067\n",
            "Decision Tree (with Feature Selection) - MSE: 67270120842.977135, RMSE: 259364.84118510963, R2: 0.2815590129715615\n",
            "Random Forest (with Feature Selection) - MSE: 43195334124.8937, MSE: 207834.87225413762, R2: 0.5386763381003851\n",
            "Gradient Boosting (with Feature Selection) - MSE: 43916098155.45207, RMSE: 209561.68102840765, R2: 0.5309786200787738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter Tunning"
      ],
      "metadata": {
        "id": "yyXXBFgR8xsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example hyperparameter grid for Linear Regression (you'll need to define similar grids for other models)\n",
        "param_grid_lr = {} # Linear regression has no hyperparameters to tune\n",
        "\n",
        "# Example hyperparameter grid for Ridge Regression\n",
        "param_grid_ridge = {'alpha': [0.1, 1.0, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "                    'solver': ['svd','auto']\n",
        "                    }\n",
        "models = {\n",
        "    'Linear Regression': (LinearRegression(), param_grid_lr),\n",
        "    'Ridge Regression': (Ridge(), param_grid_ridge)\n",
        "}\n",
        "\n",
        "for df in df_seperated:\n",
        "    X = df.drop(columns=['Price'])\n",
        "    y = df['Price']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature Selection\n",
        "    selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    for model_name, (model, param_grid) in models.items():\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "        grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        y_pred = best_model.predict(X_test_selected)\n",
        "\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "        print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siOd8-K5GoVH",
        "outputId": "c7305bdb-e987-4117-c3a2-7d80786e1bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (with Feature Selection) - Best Hyperparameters: {}\n",
            "Linear Regression (with Feature Selection) - MSE: 85141935874.85558, RMSE: 291790.9112272957, R2: 0.7057605497968791\n",
            "Ridge Regression (with Feature Selection) - Best Hyperparameters: {'alpha': 0.7, 'solver': 'svd'}\n",
            "Ridge Regression (with Feature Selection) - MSE: 85328514935.97731, RMSE: 292110.44989177864, R2: 0.7051157568426225\n",
            "Linear Regression (with Feature Selection) - Best Hyperparameters: {}\n",
            "Linear Regression (with Feature Selection) - MSE: 28661108267.063, RMSE: 169295.91922743738, R2: 0.7329174743521125\n",
            "Ridge Regression (with Feature Selection) - Best Hyperparameters: {'alpha': 0.5, 'solver': 'svd'}\n",
            "Ridge Regression (with Feature Selection) - MSE: 28487202269.60788, RMSE: 168781.52229911863, R2: 0.7345380415888305\n",
            "Linear Regression (with Feature Selection) - Best Hyperparameters: {}\n",
            "Linear Regression (with Feature Selection) - MSE: 51148554315.06116, RMSE: 226160.4614318364, R2: 0.45373640798169357\n",
            "Ridge Regression (with Feature Selection) - Best Hyperparameters: {'alpha': 0.8, 'solver': 'auto'}\n",
            "Ridge Regression (with Feature Selection) - MSE: 49043887114.53724, RMSE: 221458.54491199303, R2: 0.47621413155291026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example hyperparameter grid for RandomForestRegressor\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 500],\n",
        "    'max_depth': [None, 10, 20]\n",
        "}\n",
        "models = {\n",
        "    'Random Forest': (RandomForestRegressor(random_state=42), param_grid_rf)\n",
        "}\n",
        "for df in df_seperated:\n",
        "    X = df.drop(columns=['Price'])\n",
        "    y = df['Price']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature Selection\n",
        "    selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    for model_name, (model, param_grid) in models.items():\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "        grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        y_pred = best_model.predict(X_test_selected)\n",
        "\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "        print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCj_SCjmG6eT",
        "outputId": "776dacdc-afe0-4a49-ce71-3031caff6607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (with Feature Selection) - Best Hyperparameters: {'max_depth': None, 'n_estimators': 500}\n",
            "Random Forest (with Feature Selection) - MSE: 63872107269.46831, RMSE: 252729.3162050424, R2: 0.7792663094493564\n",
            "Random Forest (with Feature Selection) - Best Hyperparameters: {'max_depth': None, 'n_estimators': 500}\n",
            "Random Forest (with Feature Selection) - MSE: 19359089381.15603, RMSE: 139136.9447025341, R2: 0.819599631738449\n",
            "Random Forest (with Feature Selection) - Best Hyperparameters: {'max_depth': 20, 'n_estimators': 500}\n",
            "Random Forest (with Feature Selection) - MSE: 44754260478.16957, RMSE: 211552.02782807252, R2: 0.5220270951093331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example hyperparameter grid for GradientBoostingRegressor\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 500],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "models = {\n",
        "    'Gradient Boosting': (GradientBoostingRegressor(random_state=42), param_grid_gb)\n",
        "}\n",
        "\n",
        "for df in df_seperated:\n",
        "    X = df.drop(columns=['Price'])\n",
        "    y = df['Price']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature Selection\n",
        "    selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    for model_name, (model, param_grid) in models.items():\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "        grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        y_pred = best_model.predict(X_test_selected)\n",
        "\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "        print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")\n"
      ],
      "metadata": {
        "id": "BR4betaC8wo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6649d44f-5209-40fa-b81a-cd562fed06de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting (with Feature Selection) - Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}\n",
            "Gradient Boosting (with Feature Selection) - MSE: 61525742515.03478, RMSE: 248043.83184234754, R2: 0.7873750406900374\n",
            "Gradient Boosting (with Feature Selection) - Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 500}\n",
            "Gradient Boosting (with Feature Selection) - MSE: 23773932089.01486, RMSE: 154187.97647357223, R2: 0.7784593056294222\n",
            "Gradient Boosting (with Feature Selection) - Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 500}\n",
            "Gradient Boosting (with Feature Selection) - MSE: 41892354569.22119, RMSE: 204676.21886584966, R2: 0.5525920841452052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meta Regressor"
      ],
      "metadata": {
        "id": "0HKa7wT79KIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta regressor for the first subset\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Define the base models\n",
        "estimators = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('ridge', Ridge(alpha = 0.7, solver = 'svd')),\n",
        "    ('gb', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 5, min_samples_split = 5, n_estimators = 500, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(max_depth=None, n_estimators=500, random_state=42))\n",
        "]\n",
        "\n",
        "# Define the meta-learner\n",
        "final_estimator = LinearRegression()\n",
        "\n",
        "# Create the stacking regressor\n",
        "meta_model = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "X = df_preprocess_H.drop(columns=['Price'])\n",
        "y = df_preprocess_H['Price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Train the meta-model\n",
        "meta_model.fit(X_train_selected, y_train)\n",
        "y_pred = meta_model.predict(X_test_selected)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Meta-Model - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHbVf5jVpQZ3",
        "outputId": "25e8950a-b005-4da5-fb6f-04d1f4f0492f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Model - MSE: 57564890690.09752, RMSE: 239926.84445492446, R2: 0.8010632291406568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta regressor for the second subset\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Define the base models\n",
        "estimators = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('ridge', Ridge(alpha = 0.5, solver = 'svd')),\n",
        "    ('gb', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 5, min_samples_split = 2, n_estimators = 500, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(max_depth=None, n_estimators=500, random_state=42))\n",
        "]\n",
        "\n",
        "# Define the meta-learner\n",
        "final_estimator = LinearRegression()\n",
        "\n",
        "# Create the stacking regressor\n",
        "meta_model = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "X = df_preprocess_R.drop(columns=['Price'])\n",
        "y = df_preprocess_R['Price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Train the meta-model\n",
        "meta_model.fit(X_train_selected, y_train)\n",
        "y_pred = meta_model.predict(X_test_selected)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Meta-Model - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "kvo3Gy00RnZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98596374-9b3a-47e1-9171-d7b1dea7bdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Model - MSE: 18224556339.427265, RMSE: 134998.35680269322, R2: 0.8301719357607646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta regressor for the third subset\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Define the base models\n",
        "estimators = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('ridge', Ridge(alpha = 0.8, solver = 'auto')),\n",
        "    ('gb', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 5, min_samples_split = 5, n_estimators = 500, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(max_depth=20, n_estimators=500, random_state=42))\n",
        "]\n",
        "\n",
        "# Define the meta-learner\n",
        "final_estimator = LinearRegression()\n",
        "\n",
        "# Create the stacking regressor\n",
        "meta_model = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "\n",
        "X = df_preprocess_S.drop(columns=['Price'])\n",
        "y = df_preprocess_S['Price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Selection\n",
        "selector = SelectKBest(score_func=f_regression, k=550)  # Select top 550 features\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Train the meta-model\n",
        "meta_model.fit(X_train_selected, y_train)\n",
        "y_pred = meta_model.predict(X_test_selected)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Meta-Model - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHjQyOICx5Wt",
        "outputId": "7c621496-9728-46e9-e79a-a65218f02d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Model - MSE: 41601216395.49256, RMSE: 203963.76245669858, R2: 0.5557014229463573\n"
          ]
        }
      ]
    }
  ]
}