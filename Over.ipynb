{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ol6jUpyxZHcy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cleaned_canada.csv')\n",
        "df_preprocess = df.copy()"
      ],
      "metadata": {
        "id": "35nQHPQ1ZMvN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features with too many missing value\n",
        "missing_thresh = 0.6\n",
        "drop_cols = [col for col in df_preprocess.columns if df_preprocess[col].isnull().mean() > missing_thresh]\n",
        "df_preprocess.drop(columns=drop_cols, inplace=True)\n",
        "df_preprocess.drop(columns=['Acreage'], inplace=True)"
      ],
      "metadata": {
        "id": "b41L57g7ZjWT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df_25M = df_preprocess[df_preprocess['Price'] > 2500000].copy()\n",
        "df_25M.drop(columns=['Latitude', 'Longitude'], inplace=True)\n",
        "num_cols = df_25M.drop(columns=['Price']).select_dtypes(include=[\"float64\", \"int\"]).columns.tolist()\n",
        "cat_cols = df_25M.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "# deal with missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df_25M[cat_cols] = imputer.fit_transform(df_25M[cat_cols])\n",
        "# OneHot Coding\n",
        "df_25M = pd.get_dummies(df_25M, columns=cat_cols, dummy_na=False)\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "df_25M[num_cols] = scaler.fit_transform(df_25M[num_cols])"
      ],
      "metadata": {
        "id": "mtbd2wglZWMW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_25M = df_25M.drop(columns=['Price'])\n",
        "y_25M = df_25M['Price']\n",
        "X_train_25M, X_test_25M, y_train_25M, y_test_25M = train_test_split(X_25M, y_25M, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tSpq79OzZZ7K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "model_lr_25M = LinearRegression()\n",
        "model_lr_25M.fit(X_train_25M, y_train_25M)\n",
        "y_pred_lr_25M = model_lr_25M.predict(X_test_25M)\n",
        "mse_lr_25M = mean_squared_error(y_test_25M, y_pred_lr_25M)\n",
        "rmse_lr_25M = np.sqrt(mse_lr_25M)\n",
        "r2_lr_25M = r2_score(y_test_25M, y_pred_lr_25M)\n",
        "norm_mse_lr_25M = mse_lr_25M / (max(y_test_25M) - min(y_test_25M))\n",
        "\n",
        "print(f\"Linear Regression (>2.5M) - MSE: {mse_lr_25M}, RMSE: {rmse_lr_25M}, R2: {r2_lr_25M}, NormalizedMSE: {norm_mse_lr_25M}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0uGSJwYZkkI",
        "outputId": "d29f3bdc-ac08-4554-d102-b77ada82172a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (>2.5M) - MSE: 5900633253583.602, RMSE: 2429121.90998797, R2: 0.1793921035324575, NormalizedMSE: 223840.8574894709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge Regression\n",
        "from sklearn.linear_model import Ridge\n",
        "model_ridge_25M = Ridge(alpha=0.1)\n",
        "model_ridge_25M.fit(X_train_25M, y_train_25M)\n",
        "y_pred_ridge_25M = model_ridge_25M.predict(X_test_25M)\n",
        "mse_ridge_25M = mean_squared_error(y_test_25M, y_pred_ridge_25M)\n",
        "rmse_ridge_25M = np.sqrt(mse_ridge_25M)\n",
        "r2_ridge_25M = r2_score(y_test_25M, y_pred_ridge_25M)\n",
        "norm_mse_ridge_25M = mse_ridge_25M / (max(y_test_25M) - min(y_test_25M))\n",
        "\n",
        "print(f\"Ridge Regression (>2.5M) - MSE: {mse_ridge_25M}, RMSE: {rmse_ridge_25M}, R2: {r2_ridge_25M}, NormalizedMSE: {norm_mse_ridge_25M}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSJsfVr-ZogO",
        "outputId": "f9821955-5edf-47ae-fe98-f4792f200430"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression (>2.5M) - MSE: 5842983102444.309, RMSE: 2417226.3242080393, R2: 0.1874095767805568, NormalizedMSE: 221653.89573285272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "model_gb_25M = GradientBoostingRegressor(random_state=42)\n",
        "model_gb_25M.fit(X_train_25M, y_train_25M)\n",
        "y_pred_gb_25M = model_gb_25M.predict(X_test_25M)\n",
        "mse_gb_25M = mean_squared_error(y_test_25M, y_pred_gb_25M)\n",
        "rmse_gb_25M = np.sqrt(mse_gb_25M)\n",
        "r2_gb_25M = r2_score(y_test_25M, y_pred_gb_25M)\n",
        "norm_mse_gb_25M = mse_gb_25M / (max(y_test_25M) - min(y_test_25M))\n",
        "\n",
        "print(f\"Gradient Boosting (>2.5M) - MSE: {mse_gb_25M}, RMSE: {rmse_gb_25M}, R2: {r2_gb_25M}, NormalizedMSE: {norm_mse_gb_25M}\")"
      ],
      "metadata": {
        "id": "wLCTGLRCazck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf_25M = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "model_rf_25M.fit(X_train_25M, y_train_25M)\n",
        "y_pred_rf_25M = model_rf_25M.predict(X_test_25M)\n",
        "\n",
        "mse_rf_25M = mean_squared_error(y_test_25M, y_pred_rf_25M)\n",
        "rmse_rf_25M = np.sqrt(mse_rf_25M)\n",
        "r2_rf_25M = r2_score(y_test_25M, y_pred_rf_25M)\n",
        "norm_mse_rf_25M = mse_rf_25M / (max(y_test_25M) - min(y_test_25M))\n",
        "\n",
        "print(f\"Random Forest (>2.5M) - MSE: {mse_rf_25M}, RMSE: {rmse_rf_25M}, R2: {r2_rf_25M}, NormalizedMSE: {norm_mse_rf_25M}\")"
      ],
      "metadata": {
        "id": "YAXl6Z1qa1-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model_dt_25M = DecisionTreeRegressor(random_state=42)\n",
        "model_dt_25M.fit(X_train_25M, y_train_25M)\n",
        "y_pred_dt_25M = model_dt_25M.predict(X_test_25M)\n",
        "mse_dt_25M = mean_squared_error(y_test_25M, y_pred_dt_25M)\n",
        "rmse_dt_25M = np.sqrt(mse_dt_25M)\n",
        "r2_dt_25M = r2_score(y_test_25M, y_pred_dt_25M)\n",
        "norm_mse_dt_25M = mse_dt_25M / (max(y_test_25M) - min(y_test_25M))\n",
        "\n",
        "print(f\"Decision Tree (>2.5M) - MSE: {mse_dt_25M}, RMSE: {rmse_dt_25M}, R2: {r2_dt_25M}, NormalizedMSE: {norm_mse_dt_25M}\")"
      ],
      "metadata": {
        "id": "ccj_UQG7a4u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter grid for Ridge Regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid_ridge = {'alpha': [0.1, 1.0, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "                    'solver': ['svd','auto']\n",
        "                    }\n",
        "models = {\n",
        "    'Ridge Regression': (Ridge(), param_grid_ridge)\n",
        "}\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train_25M, y_train_25M)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_25M)\n",
        "    mse = mean_squared_error(y_test_25M, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test_25M, y_pred)\n",
        "    print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "    print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "7JH3_Sy_a7dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameter tunning for rf\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 500],\n",
        "    'max_depth': [None, 10, 20]\n",
        "}\n",
        "models = {\n",
        "    'Random Forest': (RandomForestRegressor(random_state=42), param_grid_rf)\n",
        "}\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train_25M, y_train_25M)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_25M)\n",
        "    mse = mean_squared_error(y_test_25M, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test_25M, y_pred)\n",
        "    print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "    print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "eQ9ug2eea-SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameter tunning for gradient boosting\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 500],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "models = {\n",
        "    'Gradient Boosting': (GradientBoostingRegressor(random_state=42), param_grid_gb)\n",
        "}\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')  # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train_25M, y_train_25M)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_25M)\n",
        "    mse = mean_squared_error(y_test_25M, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test_25M, y_pred)\n",
        "    print(f\"{model_name} (with Feature Selection) - Best Hyperparameters: {grid_search.best_params_}\")\n",
        "    print(f\"{model_name} (with Feature Selection) - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "1UZTa4NYbL9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta regressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "estimators = [\n",
        "    ('lr', LinearRegression()),\n",
        "    ('ridge', Ridge(alpha = 1.0, solver = 'auto')),\n",
        "    ('gb', GradientBoostingRegressor(learning_rate = 0.1, max_depth = 3, min_samples_split = 2, n_estimators = 100, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(max_depth=10, n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "# Define the meta-learner\n",
        "final_estimator = LinearRegression()\n",
        "\n",
        "# Create the stacking regressor\n",
        "meta_model = StackingRegressor(estimators=estimators, final_estimator=final_estimator, cv=5)\n",
        "meta_model.fit(X_train_25M, y_train_25M)\n",
        "y_pred_25M = meta_model.predict(X_test_25M)\n",
        "mse = mean_squared_error(y_test_25M, y_pred_25M)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_25M, y_pred_25M)\n",
        "\n",
        "print(f\"Meta-Model - MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "FWZmIj8gbUKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}